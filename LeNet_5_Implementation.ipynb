{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet-5 Implementation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOp2ZJ6JCrTfUx76s1Y+eXV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aniket1313/Computer-Vision-/blob/master/LeNet_5_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-OOt9oYN3eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"LeNet-5 Tensorflow.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1krr-CB3V0ARvZOVnh1tNglMVq8PkN6SE\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorflow_version 2.x\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
        "\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\"\"\"The goal of ùêøùëíùëÅùëíùë°‚àí5 was to recognize handwritten digits. So, it takes as an input 32√ó32√ó1 image. It is a grayscale image, thus the number of channels is 1. Below we can see an arhitecture of this network\n",
        "Let‚Äôs start with importing all necessary libraries. After imports, we can use imported module to load data. The load_data()\n",
        "          function will automatically download and split our data into training and test sets.\n",
        "\"\"\"\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(x_train[0].shape, 'image shape')\n",
        "\n",
        "\"\"\"We can check the shape of new data and see that our 28√ó28.  images are 28√ó28 pixels, so we need to add a new axis, \n",
        "        which will represent a number of channels.\n",
        "        Also, it is important to do one-hot encoding of labels and normalization of input images.\n",
        "\"\"\"\n",
        "\n",
        "# Add a new axis\n",
        "x_train = x_train[:, :, :, np.newaxis]\n",
        "x_test = x_test[:, :, :, np.newaxis]\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print(x_train[0].shape, 'image shape')\n",
        "\n",
        "\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Data normalization\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\"\"\"Now, it is time to start using TensorFlow 2.0 in order to build our convolutional neural network. \n",
        "          The easiest way to do this is by using the Sequential API. We will wrap it in a class called LeNet. \n",
        "          The input is an image, and the output will be a class probability vector.\n",
        "\"\"\"\n",
        "\n",
        "# LeNet-5 model\n",
        "class LeNet(Sequential):\n",
        "  def __init__(self, input_shape, nb_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.add(Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='tanh', input_shape=input_shape, padding=\"same\"))\n",
        "    self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "    self.add(Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='tanh', padding='valid'))\n",
        "    self.add(AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "    self.add(Flatten())\n",
        "    self.add(Dense(120, activation='tanh'))\n",
        "    self.add(Dense(84, activation='tanh'))\n",
        "    self.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "    self.compile(optimizer='adam',\n",
        "                loss=categorical_crossentropy,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model = LeNet(x_train[0].shape, num_classes)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Place the logs in a timestamped subdirectory\n",
        "# This allows to easy select different training runs\n",
        "# In order not to overwrite some data, it is useful to have a name with a timestamp\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Specify the callback object\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "# tf.keras.callback.TensorBoard ensures that logs are created and stored\n",
        "# We need to pass callback object to the fit method\n",
        "# The way to do this is by passing the list of callback objects, which is in our case just one\n",
        "\n",
        "model.fit(x_train, y=y_train, \n",
        "          epochs=20, \n",
        "          validation_data=(x_test, y_test), \n",
        "          callbacks=[tensorboard_callback],\n",
        "          verbose=0)\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorboard --logdir logs/fit\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "prediction_values = model.predict_classes(x_test)\n",
        "\n",
        "# set up the figure\n",
        "fig = plt.figure(figsize=(15, 7))\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "\n",
        "# plot the images: each image is 28x28 pixels\n",
        "for i in range(50):\n",
        "  ax = fig.add_subplot(5, 10, i + 1, xticks=[], yticks=[])\n",
        "  ax.imshow(x_test[i,:].reshape((28,28)),cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "  \n",
        "  if prediction_values[i] == np.argmax(y_test[i]):\n",
        "    # label the image with the blue text\n",
        "    ax.text(0, 7, class_names[prediction_values[i]], color='blue')\n",
        "  else:\n",
        "    # label the image with the red text\n",
        "    ax.text(0, 7, class_names[prediction_values[i]], color='red')\n",
        "\n",
        "\"\"\"---\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCYtqBemOObU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# %tensorflow_version 2.x\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "\n",
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D\n",
        "\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lP7P3whOOeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H79KlnoTOOn8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFVvJncBOOq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhjQ4GJjOOwp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_pzeCRFOOzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RmkzxjTOO2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDPeZtSVRowt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJZY5S3qRo2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWF60DeSRpC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}